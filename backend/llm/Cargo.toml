[package]
name = "linggen-llm"
version = { workspace = true }
authors = { workspace = true }
edition = { workspace = true }


[dependencies]
# Candle ML framework (using git for latest Qwen3 support)
candle-core = { git = "https://github.com/huggingface/candle.git" }
candle-transformers = { git = "https://github.com/huggingface/candle.git" }
candle-nn = { git = "https://github.com/huggingface/candle.git" }

# Tokenization
tokenizers = { version = "0.21", default-features = false, features = ["onig"] }

# Model downloading from Hugging Face
hf-hub = "0.4"

# Utilities
anyhow = "1.0"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
thiserror = "2.0"
dirs = "5.0"
rand = "0.8"
chrono = "=0.4"
tracing = "0.1"

# Async
tokio = { version = "1.42", features = ["full"] }

[target.'cfg(target_os = "macos")'.dependencies]
candle-core = { git = "https://github.com/huggingface/candle.git", features = ["metal"] }
candle-transformers = { git = "https://github.com/huggingface/candle.git", features = ["metal"] }
candle-nn = { git = "https://github.com/huggingface/candle.git", features = ["metal"] }

[features]
# GPU acceleration
cuda = ["candle-core/cuda", "candle-nn/cuda", "candle-transformers/cuda"]
